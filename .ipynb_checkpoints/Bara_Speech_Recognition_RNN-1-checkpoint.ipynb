{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import keras\n",
    "import librosa\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.layers import * \n",
    "from keras.layers import Input, Activation, LSTM\n",
    "from keras.layers import Dense, Dropout, Bidirectional\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = input()\n",
    "#speech_recognition_dataset/train/audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Find All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Categories:  30\n",
      "['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    }
   ],
   "source": [
    "categories = [f for f in listdir(dir_path) if isdir(join(dir_path, f))]\n",
    "categories.sort()\n",
    "categories.remove('.ipynb_checkpoints')\n",
    "print('Number of Categories: ', len(categories[1:]))\n",
    "print(categories[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target List:  ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
      "\n",
      "Unknowns List :  ['bed', 'bird', 'cat', 'dog', 'eight', 'five', 'four', 'happy', 'house', 'marvin', 'nine', 'one', 'seven', 'sheila', 'six', 'three', 'tree', 'two', 'wow', 'zero']\n"
     ]
    }
   ],
   "source": [
    "target_list = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "unknown_list = [d for d in categories if d not in target_list and d != '_background_noise_' ]\n",
    "print('Target List: ', target_list)\n",
    "print('\\nUnknowns List : ', unknown_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'background_noise_mfcc.memmap'\n",
    "#393 is the number of the Silence Examples\n",
    "fpc = np.memmap(file_name, dtype='float32', mode='r', shape=((393) * 101,20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_noise = []\n",
    "with open('background_noise_label.txt') as f:\n",
    "    background_noise_label = f.readlines()\n",
    "for i in range(0, len(background_noise_label)):\n",
    "    x = fpc[i*101:(i+1)*101, :]\n",
    "    y = background_noise_label[i].strip()\n",
    "    background_noise.append([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'all_waves_mfcc.memmap'\n",
    "#58252 is the number of the Known and Unknown Examples\n",
    "fpc = np.memmap(file_name, dtype='float32', mode='r', shape=((58252) * 101,20)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset_wav = []\n",
    "unknown_wav = []\n",
    "label_all = []\n",
    "with open('all_waves_label.txt') as f:\n",
    "    all_waves_label = f.readlines()\n",
    "for i in range(0, len(all_waves_label)):\n",
    "    mfcc = fpc[i*101:(i+1)*101, :]\n",
    "    y = all_waves_label[i].strip()\n",
    "    if y in unknown_list:\n",
    "        unknown_wav.append(mfcc)\n",
    "    else:\n",
    "        all_dataset_wav.append([mfcc, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "waves = np.reshape(np.delete(all_dataset_wav,1,1),(len(all_dataset_wav)))\n",
    "label_all = [i for i in np.delete(all_dataset_wav,0,1).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_values = np.array([x for x in waves])\n",
    "label_values = [x for x in label_all]\n",
    "label_values = np.array(label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36940, 101, 20) (21312, 101, 20)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(unknown_wav).shape, wave_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 101, 20) (6000, 1)\n"
     ]
    }
   ],
   "source": [
    "unknown = unknown_wav\n",
    "np.random.shuffle(unknown)\n",
    "unknown = np.array(unknown)\n",
    "unknown = unknown[:2000*(3)]\n",
    "unknown_label = np.array(['unknown' for _ in range(2000*(3))])\n",
    "unknown_label = unknown_label.reshape(2000*(3),1)\n",
    "print(unknown.shape, unknown_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wav_silence = np.reshape(np.delete(background_noise,1,1),(len(background_noise)))\n",
    "silence_wave = np.array([x for x in wav_silence])\n",
    "silence_label = np.array(['silence' for _ in range(len(background_noise))])\n",
    "silence_label = silence_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21312, 101, 20) (21312, 1)\n",
      "(6000, 101, 20) (6000, 1)\n",
      "(393, 101, 20) (393, 1)\n"
     ]
    }
   ],
   "source": [
    "print(wave_values.shape, label_values.shape)\n",
    "print(unknown.shape, unknown_label.shape)\n",
    "print(silence_wave.shape, silence_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27705 27705\n"
     ]
    }
   ],
   "source": [
    "wave_values = np.concatenate((wave_values, silence_wave), axis = 0)\n",
    "wave_values = np.concatenate((wave_values, unknown), axis = 0)\n",
    "label_values = np.concatenate((label_values, unknown_label), axis = 0)\n",
    "label_values = np.concatenate((label_values, silence_label), axis = 0)\n",
    "print(len(wave_values), len(label_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(wave_values, label_values, \n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state = 1993,\n",
    "                                                                   shuffle=True)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, \n",
    "                                                            test_size=0.2,\n",
    "                                                            random_state = 1993,\n",
    "                                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_value = target_list\n",
    "label_value.append('unknown')\n",
    "label_value.append('silence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Convert to one hot vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': 0, 'no': 1, 'up': 2, 'down': 3, 'left': 4, 'right': 5, 'on': 6, 'off': 7, 'stop': 8, 'go': 9, 'unknown': 10, 'silence': 11}\n"
     ]
    }
   ],
   "source": [
    "new_label_value = dict()\n",
    "for i, l in enumerate(label_value):\n",
    "    new_label_value[l] = i\n",
    "label_value = new_label_value\n",
    "print(label_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "cnt = 0\n",
    "\n",
    "for v in Y_train:\n",
    "    temp.append(label_value[v[0]])\n",
    "Y_train = np.array(temp)\n",
    "\n",
    "temp = []\n",
    "for v in Y_val:\n",
    "    temp.append(label_value[v[0]])\n",
    "Y_val = np.array(temp)\n",
    "\n",
    "temp = []\n",
    "for v in Y_test:\n",
    "    temp.append(label_value[v[0]])\n",
    "Y_test = np.array(temp)\n",
    "\n",
    "#Make Label data 'class num' -> 'One hot vector'\n",
    "Y_train = keras.utils.to_categorical(Y_train, len(label_value))\n",
    "Y_val = keras.utils.to_categorical(Y_val, len(label_value))\n",
    "Y_test = keras.utils.to_categorical(Y_test, len(label_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, X_train.shape[1], X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Wav Demension : (17731, 101, 20)\n",
      "Train_Label Demension : (17731, 12)\n",
      "Validation_Wav Demension : (4433, 101, 20)\n",
      "Validation_Label Demension : (4433, 12)\n",
      "Test_Wav Demension : (5541, 101, 20)\n",
      "Test_Label Demension : (5541, 12)\n",
      "Number Of Labels : 12\n"
     ]
    }
   ],
   "source": [
    "print('Train_Wav Demension : ' + str(np.shape(X_train)))\n",
    "print('Train_Label Demension : ' + str(np.shape(Y_train)))\n",
    "print('Validation_Wav Demension : ' + str(np.shape(X_val)))\n",
    "print('Validation_Label Demension : ' + str(np.shape(Y_val)))\n",
    "print('Test_Wav Demension : ' + str(np.shape(X_test)))\n",
    "print('Test_Label Demension : ' + str(np.shape(Y_test)))\n",
    "print('Number Of Labels : ' + str(len(label_value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=((101, 20)))\n",
    "blstm1 = Bidirectional(LSTM(units=256 ,return_sequences=True,kernel_initializer=glorot_normal(seed=961)))(inputs)\n",
    "dropout1 = Dropout(0.5)(blstm1)\n",
    "blstm2 = Bidirectional(LSTM(units=256 ,return_sequences=False,kernel_initializer=glorot_normal(seed=961)))(dropout1)\n",
    "dropout2 = Dropout(0.5)(blstm2)\n",
    "dense1 = Dense(units=512, activation='relu', kernel_initializer=glorot_normal(seed=961))(dropout2)\n",
    "dense2 = Dense(units=512, activation='relu', kernel_initializer=glorot_normal(seed=961))(dense1)\n",
    "output = Dense(units=len(label_value),  activation='softmax', kernel_initializer=glorot_normal(seed=961))(dense2)\n",
    "model = Model(inputs, output)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Adam(lr = 0.001),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 101, 20)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 101, 512)          567296    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 101, 512)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                6156      \n",
      "=================================================================\n",
      "Total params: 2,673,676\n",
      "Trainable params: 2,673,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 17731 samples, validate on 4433 samples\n",
      "Epoch 1/15\n",
      "17731/17731 [==============================] - 324s 18ms/step - loss: 2.0463 - accuracy: 0.3001 - val_loss: 1.4243 - val_accuracy: 0.4821\n",
      "Epoch 2/15\n",
      "17731/17731 [==============================] - 298s 17ms/step - loss: 1.2025 - accuracy: 0.5854 - val_loss: 0.9900 - val_accuracy: 0.6621\n",
      "Epoch 3/15\n",
      "17731/17731 [==============================] - 311s 18ms/step - loss: 0.8593 - accuracy: 0.7114 - val_loss: 0.7533 - val_accuracy: 0.7519\n",
      "Epoch 4/15\n",
      "17731/17731 [==============================] - 336s 19ms/step - loss: 0.6679 - accuracy: 0.7832 - val_loss: 0.6415 - val_accuracy: 0.7922\n",
      "Epoch 5/15\n",
      "17731/17731 [==============================] - 324s 18ms/step - loss: 0.5699 - accuracy: 0.8187 - val_loss: 0.5606 - val_accuracy: 0.8277\n",
      "Epoch 6/15\n",
      "17731/17731 [==============================] - 344s 19ms/step - loss: 0.4845 - accuracy: 0.8448 - val_loss: 0.5254 - val_accuracy: 0.8333\n",
      "Epoch 7/15\n",
      "17731/17731 [==============================] - 304s 17ms/step - loss: 0.4141 - accuracy: 0.8684 - val_loss: 0.4939 - val_accuracy: 0.8482\n",
      "Epoch 8/15\n",
      "17731/17731 [==============================] - 377s 21ms/step - loss: 0.3671 - accuracy: 0.8822 - val_loss: 0.5124 - val_accuracy: 0.8437\n",
      "Epoch 9/15\n",
      "17731/17731 [==============================] - 708s 40ms/step - loss: 0.3299 - accuracy: 0.8937 - val_loss: 0.4909 - val_accuracy: 0.8637\n",
      "Epoch 10/15\n",
      "17731/17731 [==============================] - 390s 22ms/step - loss: 0.3076 - accuracy: 0.9025 - val_loss: 0.4410 - val_accuracy: 0.8660\n",
      "Epoch 11/15\n",
      "17731/17731 [==============================] - 336s 19ms/step - loss: 0.2764 - accuracy: 0.9126 - val_loss: 0.4331 - val_accuracy: 0.8798\n",
      "Epoch 12/15\n",
      "17731/17731 [==============================] - 340s 19ms/step - loss: 0.2456 - accuracy: 0.9218 - val_loss: 0.4833 - val_accuracy: 0.8746\n",
      "Epoch 13/15\n",
      "17731/17731 [==============================] - 346s 20ms/step - loss: 0.2330 - accuracy: 0.9261 - val_loss: 0.4160 - val_accuracy: 0.8874\n",
      "Epoch 14/15\n",
      "17731/17731 [==============================] - 353s 20ms/step - loss: 0.2151 - accuracy: 0.9329 - val_loss: 0.4495 - val_accuracy: 0.8762\n",
      "Epoch 15/15\n",
      "17731/17731 [==============================] - 661s 37ms/step - loss: 0.2138 - accuracy: 0.9322 - val_loss: 0.4377 - val_accuracy: 0.8822\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=[X_val, Y_val],\n",
    "          batch_size=512, \n",
    "          epochs=15,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5541/5541 [==============================] - 118s 21ms/step\n",
      "Test accuracy: 0.8780003786087036\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
